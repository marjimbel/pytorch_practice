{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "has_gpu = torch.cuda.is_available()\n",
    "print(has_gpu)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open('./datasets/borges_full.txt','r',encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request  # the lib that handles the url stuff\n",
    "# target_url = 'https://ia601201.us.archive.org/2/items/BorgesObrasCompletasBorges/Borges-Obras-Completas-Borges_djvu.txt'\n",
    "# data = urllib.request.urlopen(target_url)\n",
    "# text = data.read().decode('utf-8')\n",
    "# with open('./datasets/borges_full.txt', 'w') as f:\n",
    "#     f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiero dejar escrita una confesión que a m tiempo será \n",
      "íntima y general  ya que las cosas que le ocurren a un \n",
      "hombre les ocurren a todos Estoy hablando de algo ya \n",
      "remoto y perdido los días de mi santo t los más antiguos \n",
      "Yo recibía los regalos y yo pensaba que no era más que \n",
      "un chico y que no había hecho nada  absolutamente nada \n",
      "para merecerlos  PoY supuesto nunca lo dije la nifiez es \n",
      "tímida  Desde entonces me has dado tantas cosas y son \n",
      "tantos los años y los recuerdos  Padre Norah los abuelos \n",
      "tu memoria y en ella la memoria de los mayores  los \n",
      "patios los esclavos el agúatele la carga de los húsares \n",
      "del Perú y el oprobio de Rosas   tu prisión valerosa \n",
      "cuando tantos hombres callábamos  las mañanas del Paso \n",
      "del Molino f de Ginebra y de Austin f las compartidas cla \n",
      "ridades  T sombras tu fresca ancianidad tu amor a Dv \n",
      "ckens y a Ea de Queiroz Madre  vos misma  \n",
      "\n",
      "Aquí estamos hablando los dos  et tout le resie est litié \n",
      "rature como escribió t con excelente literatura seríame \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''.join([i for i in text if i.isalpha() or i.isspace()])\n",
    "print(text[0:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(Dataset):\n",
    "        \n",
    "    def __init__(self,sequence_length,char_level):\n",
    "        \n",
    "\n",
    "        self.char_level = char_level\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.unk_word = 'UNK'\n",
    "        self.unk_word_index = len(self.index_to_word)+1\n",
    "        self.index_to_word[self.unk_word_index] = self.unk_word\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        self.sequence_length = sequence_length\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "        \n",
    "\n",
    "    def load_words(self):\n",
    "        with open('./datasets/borges.txt','r',encoding='utf8') as f:\n",
    "            text = f.read()        \n",
    "            text = ''.join([i for i in text if i.isalpha() or i.isspace()])\n",
    "        if self.char_level==True:\n",
    "            return list(text)\n",
    "        else:\n",
    "            return text.split(' ')\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )    \n",
    "\n",
    "batch_size=10    \n",
    "sequence_length=100\n",
    "char_level = False\n",
    "    \n",
    "dataset = Dataset(sequence_length, char_level=char_level)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = dataset.load_words()\n",
    "len(set(words))\n",
    "\n",
    "print(dataset.unk_word_index)\n",
    "dataset.words_indexes.count(92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenRNN(\n",
       "  (embedding): Embedding(6089, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=1024, out_features=6089, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "dev = \"cuda:0\"\n",
    "\n",
    "class TokenRNN(nn.Module):\n",
    "    def __init__(self, dataset, use_gpu):\n",
    "        super(TokenRNN, self).__init__()\n",
    "        self.embedding_dim = 128\n",
    "        self.lstm_size = 512\n",
    "        self.num_layers = 2\n",
    "        self.bidirectional = True\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "        bir=1\n",
    "        if self.bidirectional:\n",
    "            bir=2\n",
    "        self.fc = nn.Linear(self.lstm_size*bir, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        if self.use_gpu:\n",
    "            x = x.to(device)\n",
    "        embed = self.embedding(x)\n",
    "        if self.use_gpu:\n",
    "            embed = embed.to(device)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        if self.use_gpu:\n",
    "            output = output.to(device)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        bir = 1\n",
    "        if self.bidirectional:\n",
    "            bir = 2\n",
    "        \n",
    "        h = torch.zeros(self.num_layers*bir, sequence_length, self.lstm_size)\n",
    "        if self.use_gpu:\n",
    "            h = h.to(device)\n",
    "        return (h,h)\n",
    "    \n",
    "    \n",
    "model = TokenRNN(dataset, True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " doing model.to(device) True\n",
      "{'epoch': 0, 'batch': 0, 'loss': 8.713558197021484}\n",
      "{'epoch': 0, 'batch': 500, 'loss': 5.4991278648376465}\n",
      "{'epoch': 0, 'batch': 1000, 'loss': 5.258494853973389}\n",
      "{'epoch': 1, 'batch': 0, 'loss': 6.857874393463135}\n",
      "{'epoch': 1, 'batch': 500, 'loss': 3.3809866905212402}\n",
      "{'epoch': 1, 'batch': 1000, 'loss': 2.907339096069336}\n",
      "{'epoch': 2, 'batch': 0, 'loss': 5.977495193481445}\n",
      "{'epoch': 2, 'batch': 500, 'loss': 1.9419424533843994}\n",
      "{'epoch': 2, 'batch': 1000, 'loss': 1.5021312236785889}\n",
      "{'epoch': 3, 'batch': 0, 'loss': 4.880244731903076}\n",
      "{'epoch': 3, 'batch': 500, 'loss': 0.9647094011306763}\n",
      "{'epoch': 3, 'batch': 1000, 'loss': 0.800978422164917}\n",
      "{'epoch': 4, 'batch': 0, 'loss': 3.733320713043213}\n",
      "{'epoch': 4, 'batch': 500, 'loss': 0.5864612460136414}\n",
      "{'epoch': 4, 'batch': 1000, 'loss': 0.4179871380329132}\n",
      "{'epoch': 5, 'batch': 0, 'loss': 2.725355625152588}\n",
      "{'epoch': 5, 'batch': 500, 'loss': 0.3142109811306}\n",
      "{'epoch': 5, 'batch': 1000, 'loss': 0.23613715171813965}\n",
      "{'epoch': 6, 'batch': 0, 'loss': 1.5721194744110107}\n",
      "{'epoch': 6, 'batch': 500, 'loss': 0.19170020520687103}\n",
      "{'epoch': 6, 'batch': 1000, 'loss': 0.14019498229026794}\n",
      "{'epoch': 7, 'batch': 0, 'loss': 1.1198524236679077}\n",
      "{'epoch': 7, 'batch': 500, 'loss': 0.08959095925092697}\n",
      "{'epoch': 7, 'batch': 1000, 'loss': 0.057841427624225616}\n",
      "{'epoch': 8, 'batch': 0, 'loss': 0.6000018119812012}\n",
      "{'epoch': 8, 'batch': 500, 'loss': 0.029939090833067894}\n",
      "{'epoch': 8, 'batch': 1000, 'loss': 0.01919068582355976}\n",
      "{'epoch': 9, 'batch': 0, 'loss': 0.34161391854286194}\n",
      "{'epoch': 9, 'batch': 500, 'loss': 0.011728803627192974}\n",
      "{'epoch': 9, 'batch': 1000, 'loss': 0.010748126544058323}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "epochs=10\n",
    "start = time.time()\n",
    "device = torch.device(device) \n",
    "\n",
    "def train(dataset, model):\n",
    "    print(f\" doing model.to(device) {model.use_gpu}\")\n",
    "\n",
    "    if model.use_gpu:\n",
    "        model.to(device)\n",
    "        \n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        state_h, state_c = model.init_state(sequence_length)\n",
    "        if model.use_gpu:\n",
    "            state_h = state_h.to(device)\n",
    "            state_c = state_c.to(device)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if model.use_gpu:\n",
    "                x.to(device)\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "            if model.use_gpu:\n",
    "                y_pred = y_pred.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch%500==0:\n",
    "                # print(time.time() - start)\n",
    "                # Be careful to overwrite our original name file!\n",
    "#                model_name = 'borges_second_pass.net'\n",
    "#                torch.save(model.state_dict(),model_name)\n",
    "                print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "\n",
    "train(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "------\n",
    "\n",
    "## Saving the Model\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful to overwrite our original name file!\n",
    "model_name = 'borges_second_pass.net'\n",
    "torch.save(model.state_dict(),model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenRNN(\n",
       "  (embedding): Embedding(6089, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=1024, out_features=6089, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MUST MATCH THE EXACT SAME SETTINGS AS MODEL USED DURING TRAINING!\n",
    "model_name = 'borges_second_pass.net'\n",
    "\n",
    "model = TokenRNN(dataset, False)\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el universo vocales esquina indigno (|saias ya manuscrito para mi, calificar\n",
      "de esta vio en 1912 como como un detenido un dios se claros, de\n",
      "las zaguan de confianza y una casi una pie, una refutacién de la jefes la desdefaron. es blasfematorio®. es space\n",
      "\n",
      "hamiet, es blasfematorio®. y mortifica y ser el famoso el famoso el sentenciado diecinueve, fierro de shahrazad de piel de boletines...\n",
      "\n",
      "observé de vertiginosa de vertiginosa de dialéctica, de san\n",
      "lucas.\n",
      "\n",
      "estos regresa destino. y carpécrates; un remoto\n",
      "espejo asi sagrado a mera a refleja olviden que erratas, ver a voces a voces que se aterréd el tiempo de las palabras y de el\n"
     ]
    }
   ],
   "source": [
    "def predict(dataset, model, text, next_words=100, use_gpu=False):\n",
    "    model.eval()\n",
    "    \n",
    "    if use_gpu:\n",
    "        model.to(device)\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "    if use_gpu:\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "\n",
    "    def get_index(word):\n",
    "        if word in dataset.word_to_index.keys():\n",
    "            return dataset.word_to_index[word]\n",
    "        else:\n",
    "            return dataset.unk_word_index\n",
    "    \n",
    "    for i in range(0, next_words):\n",
    "        \n",
    "        x = torch.tensor([[get_index(w) for w in words[i:]]])\n",
    "\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        last_word_logits = last_word_logits.to('cpu')\n",
    "\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words\n",
    "\n",
    "import random\n",
    "r = random.randint(0, len(dataset.words))\n",
    "text = \"\".join(dataset.words[r:r+dataset.sequence_length])\n",
    "language_generated = predict(dataset, model, text=\"el universo\", next_words=100, use_gpu=False)\n",
    "\n",
    "print(' '.join(language_generated).lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
